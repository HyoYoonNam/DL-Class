{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2f478c1-b8bf-450c-bc09-77df4606f955",
   "metadata": {},
   "source": [
    "Q. conv1d에서는 GlobalAveragePooling1D()이 더 적합해?  \n",
    "A.  \n",
    "네, Conv1D에서는 GlobalAveragePooling1D()이 더 적합합니다.\n",
    "\n",
    "Conv1D는 시계열 데이터나 1D 데이터에 대한 합성곱 연산을 수행합니다. Conv1D의 출력은 2D 데이터이지만, 시계열 데이터의 경우에는 시간 축에 대한 정보가 중요합니다. 따라서, GlobalAveragePooling1D()을 사용하여 시간 축에 대한 정보를 유지하면서 데이터의 크기를 줄일 수 있습니다.\n",
    "\n",
    "GlobalAveragePooling1D()은 Conv1D의 출력을 시간 축에 대한 평균을 계산하여 1D 데이터로 변환합니다. 이는 Conv1D의 출력을 Flatten()을 사용하여 1D 데이터로 변환하는 것보다 더 적합합니다. 왜냐하면 Flatten()은 Conv1D의 출력을 단순히 1D 데이터로 변환하지만, GlobalAveragePooling1D()은 시간 축에 대한 정보를 유지하면서 데이터의 크기를 줄이기 때문입니다.\n",
    "\n",
    "따라서, Conv1D에서는 GlobalAveragePooling1D()이 더 적합합니다.\n",
    "\n",
    "예를 들어, 다음과 같은 모델을 사용할 수 있습니다.\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(n_steps, 8)))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "```\n",
    "이 모델은 Conv1D의 출력을 GlobalAveragePooling1D()을 사용하여 시간 축에 대한 평균을 계산하고, Dense 층에 입력으로 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b4dd1-2f1e-429b-a03d-f2ca63e06fc8",
   "metadata": {},
   "source": [
    "# 기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a329d4de-c188-4a7a-89fb-b6a938e52ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 23:43:30.398724: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 23:43:34.886117: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 1s 5ms/step - loss: 0.8348 - accuracy: 0.6818 - val_loss: 0.6479 - val_accuracy: 0.7374\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7361 - val_loss: 0.5306 - val_accuracy: 0.7734\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7567 - val_loss: 0.4992 - val_accuracy: 0.7722\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.7726 - val_loss: 0.4835 - val_accuracy: 0.7854\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7813 - val_loss: 0.4643 - val_accuracy: 0.7950\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7879 - val_loss: 0.4518 - val_accuracy: 0.8034\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7849 - val_loss: 0.4537 - val_accuracy: 0.8070\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7981 - val_loss: 0.4627 - val_accuracy: 0.7950\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.8029 - val_loss: 0.4382 - val_accuracy: 0.8082\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.8080 - val_loss: 0.4618 - val_accuracy: 0.7890\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4198 - accuracy: 0.8140 - val_loss: 0.4432 - val_accuracy: 0.8034\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.8128 - val_loss: 0.4379 - val_accuracy: 0.8106\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4104 - accuracy: 0.8209 - val_loss: 0.4159 - val_accuracy: 0.8261\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3938 - accuracy: 0.8260 - val_loss: 0.4166 - val_accuracy: 0.8261\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.8281 - val_loss: 0.4163 - val_accuracy: 0.8177\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3902 - accuracy: 0.8356 - val_loss: 0.4090 - val_accuracy: 0.8237\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3803 - accuracy: 0.8413 - val_loss: 0.4191 - val_accuracy: 0.8201\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.8401 - val_loss: 0.4011 - val_accuracy: 0.8165\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3726 - accuracy: 0.8368 - val_loss: 0.4308 - val_accuracy: 0.8369\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8464 - val_loss: 0.3941 - val_accuracy: 0.8165\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8422 - val_loss: 0.3847 - val_accuracy: 0.8225\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3629 - accuracy: 0.8506 - val_loss: 0.3889 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3553 - accuracy: 0.8476 - val_loss: 0.4031 - val_accuracy: 0.8393\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8542 - val_loss: 0.3743 - val_accuracy: 0.8453\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8542 - val_loss: 0.3952 - val_accuracy: 0.8225\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8509 - val_loss: 0.3761 - val_accuracy: 0.8369\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8557 - val_loss: 0.3698 - val_accuracy: 0.8405\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8602 - val_loss: 0.3699 - val_accuracy: 0.8477\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8551 - val_loss: 0.3991 - val_accuracy: 0.8297\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8578 - val_loss: 0.3716 - val_accuracy: 0.8321\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8629 - val_loss: 0.3516 - val_accuracy: 0.8453\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8644 - val_loss: 0.3870 - val_accuracy: 0.8273\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3182 - accuracy: 0.8671 - val_loss: 0.3994 - val_accuracy: 0.8393\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3136 - accuracy: 0.8632 - val_loss: 0.3865 - val_accuracy: 0.8345\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3107 - accuracy: 0.8701 - val_loss: 0.3519 - val_accuracy: 0.8537\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3067 - accuracy: 0.8698 - val_loss: 0.3925 - val_accuracy: 0.8285\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.8704 - val_loss: 0.3484 - val_accuracy: 0.8489\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2961 - accuracy: 0.8773 - val_loss: 0.3563 - val_accuracy: 0.8489\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.8764 - val_loss: 0.3442 - val_accuracy: 0.8537\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.8779 - val_loss: 0.3936 - val_accuracy: 0.8381\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2954 - accuracy: 0.8734 - val_loss: 0.3457 - val_accuracy: 0.8513\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2907 - accuracy: 0.8842 - val_loss: 0.3394 - val_accuracy: 0.8549\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2837 - accuracy: 0.8815 - val_loss: 0.4168 - val_accuracy: 0.8201\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2937 - accuracy: 0.8812 - val_loss: 0.3417 - val_accuracy: 0.8681\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2738 - accuracy: 0.8878 - val_loss: 0.3516 - val_accuracy: 0.8525\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2780 - accuracy: 0.8836 - val_loss: 0.3413 - val_accuracy: 0.8585\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2775 - accuracy: 0.8815 - val_loss: 0.3603 - val_accuracy: 0.8393\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2702 - accuracy: 0.8851 - val_loss: 0.3652 - val_accuracy: 0.8489\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2812 - accuracy: 0.8776 - val_loss: 0.3656 - val_accuracy: 0.8417\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2652 - accuracy: 0.8950 - val_loss: 0.3362 - val_accuracy: 0.8573\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2683 - accuracy: 0.8884 - val_loss: 0.3548 - val_accuracy: 0.8501\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2785 - accuracy: 0.8815 - val_loss: 0.3448 - val_accuracy: 0.8585\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.8872 - val_loss: 0.3219 - val_accuracy: 0.8729\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2580 - accuracy: 0.8956 - val_loss: 0.3310 - val_accuracy: 0.8573\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.8941 - val_loss: 0.3605 - val_accuracy: 0.8537\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2603 - accuracy: 0.8956 - val_loss: 0.3218 - val_accuracy: 0.8693\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2557 - accuracy: 0.8944 - val_loss: 0.3446 - val_accuracy: 0.8549\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.8974 - val_loss: 0.3161 - val_accuracy: 0.8657\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.9013 - val_loss: 0.3302 - val_accuracy: 0.8621\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.8956 - val_loss: 0.3294 - val_accuracy: 0.8573\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2497 - accuracy: 0.8935 - val_loss: 0.3246 - val_accuracy: 0.8585\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.8974 - val_loss: 0.3493 - val_accuracy: 0.8609\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2408 - accuracy: 0.9016 - val_loss: 0.3252 - val_accuracy: 0.8573\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2396 - accuracy: 0.9064 - val_loss: 0.4072 - val_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2610 - accuracy: 0.8920 - val_loss: 0.3383 - val_accuracy: 0.8585\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.9073 - val_loss: 0.3259 - val_accuracy: 0.8657\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.8956 - val_loss: 0.3603 - val_accuracy: 0.8549\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9115 - val_loss: 0.3110 - val_accuracy: 0.8705\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2331 - accuracy: 0.9016 - val_loss: 0.3208 - val_accuracy: 0.8765\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9118 - val_loss: 0.3243 - val_accuracy: 0.8729\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2295 - accuracy: 0.9079 - val_loss: 0.3213 - val_accuracy: 0.8669\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.9115 - val_loss: 0.3399 - val_accuracy: 0.8561\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2335 - accuracy: 0.9022 - val_loss: 0.3806 - val_accuracy: 0.8393\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.9064 - val_loss: 0.3244 - val_accuracy: 0.8705\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2250 - accuracy: 0.9055 - val_loss: 0.3152 - val_accuracy: 0.8669\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.9115 - val_loss: 0.3435 - val_accuracy: 0.8549\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.9136 - val_loss: 0.3344 - val_accuracy: 0.8609\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9055 - val_loss: 0.3270 - val_accuracy: 0.8669\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2090 - accuracy: 0.9172 - val_loss: 0.3295 - val_accuracy: 0.8753\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.9133 - val_loss: 0.3171 - val_accuracy: 0.8741\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9100 - val_loss: 0.3266 - val_accuracy: 0.8657\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2143 - accuracy: 0.9154 - val_loss: 0.3184 - val_accuracy: 0.8765\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.9160 - val_loss: 0.2996 - val_accuracy: 0.8777\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.9178 - val_loss: 0.3159 - val_accuracy: 0.8693\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9205 - val_loss: 0.3056 - val_accuracy: 0.8753\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2114 - accuracy: 0.9160 - val_loss: 0.3629 - val_accuracy: 0.8549\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.9094 - val_loss: 0.3058 - val_accuracy: 0.8765\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2068 - accuracy: 0.9172 - val_loss: 0.3169 - val_accuracy: 0.8765\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2082 - accuracy: 0.9160 - val_loss: 0.3377 - val_accuracy: 0.8585\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2019 - accuracy: 0.9145 - val_loss: 0.3100 - val_accuracy: 0.8777\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9193 - val_loss: 0.3070 - val_accuracy: 0.8801\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9229 - val_loss: 0.3104 - val_accuracy: 0.8789\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.9112 - val_loss: 0.3140 - val_accuracy: 0.8717\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9202 - val_loss: 0.3278 - val_accuracy: 0.8573\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.9193 - val_loss: 0.3456 - val_accuracy: 0.8633\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1963 - accuracy: 0.9208 - val_loss: 0.3204 - val_accuracy: 0.8693\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1919 - accuracy: 0.9205 - val_loss: 0.3035 - val_accuracy: 0.8849\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 0.9133 - val_loss: 0.3236 - val_accuracy: 0.8585\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.9202 - val_loss: 0.3095 - val_accuracy: 0.8741\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.9241 - val_loss: 0.2955 - val_accuracy: 0.8825\n",
      "27/27 [==============================] - 0s 742us/step\n",
      "정확도: 0.882494004796163\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87        12\n",
      "           1       0.94      0.90      0.92       549\n",
      "           2       0.78      0.88      0.83       251\n",
      "           3       0.77      0.48      0.59        21\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.88       834\n",
      "   macro avg       0.68      0.62      0.64       834\n",
      "weighted avg       0.89      0.88      0.88       834\n",
      "\n",
      "혼동 행렬:\n",
      "[[ 10   2   0   0   0]\n",
      " [  0 495  52   2   0]\n",
      " [  1  28 221   1   0]\n",
      " [  0   1  10  10   0]\n",
      " [  0   0   1   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gc_dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/gc_dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/gc_dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('./datasets/abalone.csv', index_col=0)\n",
    "\n",
    "# 데이터 전처리\n",
    "df['Sex'] = df['Sex'].map({'M': 0, 'F': 1, 'I': 2})\n",
    "\n",
    "# 'Rings'를 label로 사용\n",
    "# 기존에 주어진 label에는 다음과 같은 문제가 있음\n",
    "# 1) label의 시작이 0이 아니고 1부터임\n",
    "# 2) label 값 중 28이 비어있음\n",
    "# 이 문제를 해결하기 위해 label을 새롭게 매핑\n",
    "rings_mapping = {29: 28}\n",
    "df['Rings'] = df['Rings'].replace(rings_mapping)\n",
    "\n",
    "# label을 0 ~ 27로 매핑\n",
    "rings_mapping = {}\n",
    "for i in range(len(np.unique(df['Rings']))):\n",
    "    rings_mapping = {i+1: i}\n",
    "    df['Rings'] = df['Rings'].replace(rings_mapping)\n",
    "\n",
    "# label을 범위를 묶어서 총 5개 정도의 label로 다시 구성\n",
    "label_mapping = {}\n",
    "for i in range(28):\n",
    "    if i < 5:\n",
    "        label_mapping[i] = 0\n",
    "    elif i < 10:\n",
    "        label_mapping[i] = 1\n",
    "    elif i < 15:\n",
    "        label_mapping[i] = 2\n",
    "    elif i < 20:\n",
    "        label_mapping[i] = 3\n",
    "    else:\n",
    "        label_mapping[i] = 4\n",
    "df['Rings'] = df['Rings'].replace(label_mapping)\n",
    "\n",
    "# dataset을 sequential하게 만들기\n",
    "def split_sequences_classification_majority(data, labels, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps + 1):\n",
    "        seq_x = data[i:i + n_steps]\n",
    "        seq_labels = labels[i:i + n_steps]\n",
    "        most_common_label = Counter(seq_labels).most_common(1)[0][0]\n",
    "        X.append(seq_x)\n",
    "        y.append(most_common_label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "n_steps = 10\n",
    "X = df.drop(['Rings'], axis=1)\n",
    "y = df['Rings']\n",
    "X, y = split_sequences_classification_majority(X.values, y.values, n_steps)\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X.reshape(-1, 8)).reshape(-1, n_steps, 8)\n",
    "\n",
    "# label에 대해 원핫 인코딩\n",
    "y = to_categorical(y)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 생성(1) 맥스 풀링 사용\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(n_steps, 8)))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# 모델 생성(2) 글로벌 풀링 사용\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(n_steps, 8)))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "print('정확도:', accuracy_score(y_test_class, y_pred_class))\n",
    "print('분류 보고서:')\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "print('혼동 행렬:')\n",
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d73bb-c5b1-48cb-9d7f-4a8d348fe512",
   "metadata": {},
   "source": [
    "# 상관계수 높은 feature 삭제 한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417d4f28-c836-4884-a0a6-6f5dd64ec394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "105/105 [==============================] - 1s 2ms/step - loss: 0.8748 - accuracy: 0.6911 - val_loss: 0.7013 - val_accuracy: 0.7074\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.7037 - val_loss: 0.6442 - val_accuracy: 0.6847\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.6438 - accuracy: 0.7127 - val_loss: 0.6175 - val_accuracy: 0.6978\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.6171 - accuracy: 0.7160 - val_loss: 0.6078 - val_accuracy: 0.6906\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5976 - accuracy: 0.7184 - val_loss: 0.5980 - val_accuracy: 0.7230\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.7418 - val_loss: 0.5828 - val_accuracy: 0.7074\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.7379 - val_loss: 0.5719 - val_accuracy: 0.7194\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.7490 - val_loss: 0.5586 - val_accuracy: 0.7242\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5509 - accuracy: 0.7457 - val_loss: 0.5575 - val_accuracy: 0.7470\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5378 - accuracy: 0.7519 - val_loss: 0.5482 - val_accuracy: 0.7326\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5320 - accuracy: 0.7570 - val_loss: 0.5452 - val_accuracy: 0.7410\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5252 - accuracy: 0.7576 - val_loss: 0.5363 - val_accuracy: 0.7530\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7630 - val_loss: 0.5316 - val_accuracy: 0.7470\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7729 - val_loss: 0.5362 - val_accuracy: 0.7530\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5174 - accuracy: 0.7633 - val_loss: 0.5312 - val_accuracy: 0.7662\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7741 - val_loss: 0.5286 - val_accuracy: 0.7566\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.7735 - val_loss: 0.5370 - val_accuracy: 0.7626\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.7765 - val_loss: 0.5212 - val_accuracy: 0.7662\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7756 - val_loss: 0.5148 - val_accuracy: 0.7590\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7864 - val_loss: 0.5118 - val_accuracy: 0.7674\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7849 - val_loss: 0.5109 - val_accuracy: 0.7650\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7879 - val_loss: 0.5145 - val_accuracy: 0.7686\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7804 - val_loss: 0.5015 - val_accuracy: 0.7686\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.7825 - val_loss: 0.5038 - val_accuracy: 0.7794\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7972 - val_loss: 0.5021 - val_accuracy: 0.7710\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7903 - val_loss: 0.5127 - val_accuracy: 0.7854\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7969 - val_loss: 0.4977 - val_accuracy: 0.7710\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7942 - val_loss: 0.5018 - val_accuracy: 0.7770\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7990 - val_loss: 0.5100 - val_accuracy: 0.7710\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7984 - val_loss: 0.4899 - val_accuracy: 0.7746\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7972 - val_loss: 0.4936 - val_accuracy: 0.7794\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.8008 - val_loss: 0.4883 - val_accuracy: 0.7686\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7999 - val_loss: 0.4856 - val_accuracy: 0.7770\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.8035 - val_loss: 0.4841 - val_accuracy: 0.7866\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8065 - val_loss: 0.4879 - val_accuracy: 0.7782\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.8032 - val_loss: 0.4726 - val_accuracy: 0.7938\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.8125 - val_loss: 0.4863 - val_accuracy: 0.7866\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.8146 - val_loss: 0.4904 - val_accuracy: 0.7830\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.8098 - val_loss: 0.4753 - val_accuracy: 0.7842\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.8137 - val_loss: 0.4838 - val_accuracy: 0.7926\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.8110 - val_loss: 0.4855 - val_accuracy: 0.7830\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8158 - val_loss: 0.4841 - val_accuracy: 0.7806\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.8152 - val_loss: 0.4891 - val_accuracy: 0.7770\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8173 - val_loss: 0.4640 - val_accuracy: 0.7998\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4102 - accuracy: 0.8206 - val_loss: 0.4607 - val_accuracy: 0.7998\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4052 - accuracy: 0.8269 - val_loss: 0.4574 - val_accuracy: 0.7926\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4040 - accuracy: 0.8185 - val_loss: 0.5023 - val_accuracy: 0.7770\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4126 - accuracy: 0.8179 - val_loss: 0.4590 - val_accuracy: 0.8022\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4071 - accuracy: 0.8227 - val_loss: 0.4616 - val_accuracy: 0.7938\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.4056 - accuracy: 0.8215 - val_loss: 0.4565 - val_accuracy: 0.8010\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.8263 - val_loss: 0.4656 - val_accuracy: 0.7902\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3910 - accuracy: 0.8359 - val_loss: 0.4610 - val_accuracy: 0.7830\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3990 - accuracy: 0.8302 - val_loss: 0.4635 - val_accuracy: 0.8010\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3892 - accuracy: 0.8356 - val_loss: 0.4482 - val_accuracy: 0.7974\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3894 - accuracy: 0.8353 - val_loss: 0.4622 - val_accuracy: 0.7926\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8347 - val_loss: 0.4867 - val_accuracy: 0.7902\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8362 - val_loss: 0.4396 - val_accuracy: 0.8022\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3846 - accuracy: 0.8335 - val_loss: 0.4510 - val_accuracy: 0.8058\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8362 - val_loss: 0.4393 - val_accuracy: 0.8129\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3839 - accuracy: 0.8311 - val_loss: 0.4525 - val_accuracy: 0.7998\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8386 - val_loss: 0.4357 - val_accuracy: 0.8141\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3697 - accuracy: 0.8431 - val_loss: 0.4489 - val_accuracy: 0.8082\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8428 - val_loss: 0.4450 - val_accuracy: 0.8082\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3679 - accuracy: 0.8479 - val_loss: 0.4379 - val_accuracy: 0.7998\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3702 - accuracy: 0.8413 - val_loss: 0.4372 - val_accuracy: 0.8082\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3669 - accuracy: 0.8389 - val_loss: 0.4338 - val_accuracy: 0.8141\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8506 - val_loss: 0.4279 - val_accuracy: 0.8153\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3669 - accuracy: 0.8398 - val_loss: 0.4355 - val_accuracy: 0.8094\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.8467 - val_loss: 0.4497 - val_accuracy: 0.7902\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3578 - accuracy: 0.8503 - val_loss: 0.4346 - val_accuracy: 0.8070\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3538 - accuracy: 0.8488 - val_loss: 0.4271 - val_accuracy: 0.8165\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8491 - val_loss: 0.4396 - val_accuracy: 0.8165\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3529 - accuracy: 0.8488 - val_loss: 0.4160 - val_accuracy: 0.8297\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8503 - val_loss: 0.4188 - val_accuracy: 0.8225\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3431 - accuracy: 0.8593 - val_loss: 0.4189 - val_accuracy: 0.8201\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8530 - val_loss: 0.4424 - val_accuracy: 0.8010\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3419 - accuracy: 0.8617 - val_loss: 0.4734 - val_accuracy: 0.7878\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.8506 - val_loss: 0.4133 - val_accuracy: 0.8237\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8575 - val_loss: 0.4396 - val_accuracy: 0.8141\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8587 - val_loss: 0.4163 - val_accuracy: 0.8225\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8533 - val_loss: 0.4206 - val_accuracy: 0.8165\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8638 - val_loss: 0.4121 - val_accuracy: 0.8213\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8578 - val_loss: 0.4500 - val_accuracy: 0.8034\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8587 - val_loss: 0.4225 - val_accuracy: 0.8141\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8608 - val_loss: 0.4170 - val_accuracy: 0.8213\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8644 - val_loss: 0.4217 - val_accuracy: 0.8213\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3222 - accuracy: 0.8665 - val_loss: 0.4234 - val_accuracy: 0.8141\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3188 - accuracy: 0.8674 - val_loss: 0.4158 - val_accuracy: 0.8165\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3174 - accuracy: 0.8662 - val_loss: 0.4204 - val_accuracy: 0.8237\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8680 - val_loss: 0.4138 - val_accuracy: 0.8273\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3156 - accuracy: 0.8683 - val_loss: 0.4130 - val_accuracy: 0.8261\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8650 - val_loss: 0.4228 - val_accuracy: 0.8141\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3191 - accuracy: 0.8674 - val_loss: 0.4150 - val_accuracy: 0.8201\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8680 - val_loss: 0.4304 - val_accuracy: 0.8177\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8674 - val_loss: 0.4105 - val_accuracy: 0.8345\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8695 - val_loss: 0.4075 - val_accuracy: 0.8297\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3042 - accuracy: 0.8719 - val_loss: 0.4031 - val_accuracy: 0.8369\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3108 - accuracy: 0.8695 - val_loss: 0.4186 - val_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3106 - accuracy: 0.8671 - val_loss: 0.4148 - val_accuracy: 0.8237\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.3014 - accuracy: 0.8728 - val_loss: 0.4545 - val_accuracy: 0.7962\n",
      "27/27 [==============================] - 0s 699us/step\n",
      "정확도: 0.7961630695443646\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.80      0.95      0.87       549\n",
      "           2       0.78      0.53      0.63       251\n",
      "           3       0.33      0.05      0.08        21\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.80       834\n",
      "   macro avg       0.54      0.44      0.46       834\n",
      "weighted avg       0.78      0.80      0.78       834\n",
      "\n",
      "혼동 행렬:\n",
      "[[  8   4   0   0   0]\n",
      " [  1 521  27   0   0]\n",
      " [  1 114 134   2   0]\n",
      " [  0  10  10   1   0]\n",
      " [  0   0   1   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gc_dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/gc_dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/gc_dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('./datasets/abalone.csv', index_col=0)\n",
    "\n",
    "# 데이터 전처리\n",
    "df['Sex'] = df['Sex'].map({'M': 0, 'F': 1, 'I': 2})\n",
    "\n",
    "# 'Rings'를 label로 사용\n",
    "# 기존에 주어진 label에는 다음과 같은 문제가 있음\n",
    "# 1) label의 시작이 0이 아니고 1부터임\n",
    "# 2) label 값 중 28이 비어있음\n",
    "# 이 문제를 해결하기 위해 label을 새롭게 매핑\n",
    "rings_mapping = {29: 28}\n",
    "df['Rings'] = df['Rings'].replace(rings_mapping)\n",
    "\n",
    "# label을 0 ~ 27로 매핑\n",
    "rings_mapping = {}\n",
    "for i in range(len(np.unique(df['Rings']))):\n",
    "    rings_mapping = {i+1: i}\n",
    "    df['Rings'] = df['Rings'].replace(rings_mapping)\n",
    "\n",
    "# label을 범위를 묶어서 총 5개 정도의 label로 다시 구성\n",
    "label_mapping = {}\n",
    "for i in range(28):\n",
    "    if i < 5:\n",
    "        label_mapping[i] = 0\n",
    "    elif i < 10:\n",
    "        label_mapping[i] = 1\n",
    "    elif i < 15:\n",
    "        label_mapping[i] = 2\n",
    "    elif i < 20:\n",
    "        label_mapping[i] = 3\n",
    "    else:\n",
    "        label_mapping[i] = 4\n",
    "df['Rings'] = df['Rings'].replace(label_mapping)\n",
    "\n",
    "# feature 중에서 상관계수가 매우 높은 feature 쌍을 삭제\n",
    "corr_matrix = df.drop(['Rings'], axis=1).corr()\n",
    "corr_matrix = corr_matrix.unstack()\n",
    "corr_matrix = corr_matrix[corr_matrix != 1]\n",
    "corr_matrix = corr_matrix.sort_values(ascending=False)\n",
    "\n",
    "high_corr_features = []\n",
    "for index, value in corr_matrix.items():\n",
    "    if abs(value) > 0.9:\n",
    "        high_corr_features.append(index[0])\n",
    "        high_corr_features.append(index[1])\n",
    "\n",
    "high_corr_features = list(set(high_corr_features))\n",
    "\n",
    "df = df.drop(high_corr_features[1:], axis=1)\n",
    "\n",
    "# dataset을 sequential하게 만들기\n",
    "def split_sequences_classification_majority(data, labels, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps + 1):\n",
    "        seq_x = data[i:i + n_steps]\n",
    "        seq_labels = labels[i:i + n_steps]\n",
    "        most_common_label = Counter(seq_labels).most_common(1)[0][0]\n",
    "        X.append(seq_x)\n",
    "        y.append(most_common_label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "n_steps = 10\n",
    "X = df.drop(['Rings'], axis=1)\n",
    "y = df['Rings']\n",
    "X, y = split_sequences_classification_majority(X.values, y.values, n_steps)\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X.reshape(-1, X.shape[2])).reshape(-1, n_steps, X.shape[2])\n",
    "\n",
    "# label에 대해 원핫 인코딩\n",
    "y = to_categorical(y)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 생성\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(n_steps, X.shape[2])))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "print('정확도:', accuracy_score(y_test_class, y_pred_class))\n",
    "print('분류 보고서:')\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "print('혼동 행렬:')\n",
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gc_dl",
   "language": "python",
   "name": "gc_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
